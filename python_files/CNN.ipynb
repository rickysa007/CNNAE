{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import os\n",
    "import silence_tensorflow.auto\n",
    "import tensorflow as tf\n",
    "\n",
    "def mask_unused_gpus(leave_unmasked=1):\n",
    "\n",
    "  ACCEPTABLE_AVAILABLE_MEMORY = 1024\n",
    "  COMMAND = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "\n",
    "  try:\n",
    "    _output_to_list = lambda x: x.decode('ascii').split('\\n')[:-1]\n",
    "    memory_free_info = _output_to_list(sp.check_output(COMMAND.split()))[1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    available_gpus = [i for i, x in enumerate(memory_free_values) if x > ACCEPTABLE_AVAILABLE_MEMORY]\n",
    "\n",
    "    if len(available_gpus) < leave_unmasked: raise ValueError('Found only %d usable GPUs in the system' % len(available_gpus))\n",
    "    gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "    tf.config.experimental.set_visible_devices(gpus[available_gpus[0]], 'GPU')\n",
    "  \n",
    "  except Exception as e:\n",
    "    print('\"nvidia-smi\" is probably not installed. GPUs are not masked', e)\n",
    "\n",
    "mask_unused_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import absl.logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from tqdm import tqdm\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ricky/RNNAE/conv_npy')\n",
    "\n",
    "data_GP = np.array(np.load('lc.npy', allow_pickle=True))\n",
    "data_meta_GP = np.array(np.load('lc_meta.npy', allow_pickle=True))\n",
    "\n",
    "print(data_GP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input(rep=32, split_portion=0.8, num_of_type=1):\n",
    "\n",
    "    claimedtype = []\n",
    "\n",
    "    input = [ [] for i in range(num_of_type+1)]\n",
    "    input_train = [ [] for i in range(num_of_type+1)]\n",
    "    input_test = [ [] for i in range(num_of_type+1)]\n",
    "    type_train = [ [] for i in range(num_of_type+1)]\n",
    "    type_test = [ [] for i in range(num_of_type+1)]\n",
    "\n",
    "    for i in range(len(data_meta_GP)):\n",
    "\n",
    "        if 'Ia' in data_meta_GP[i][-2]:\n",
    "                claimedtype.append(0)\n",
    "        if 'IIP' in data_meta_GP[i][-2]:\n",
    "                claimedtype.append(1)\n",
    "\n",
    "    for i in range(len(claimedtype)):\n",
    "\n",
    "        input[0].append(list(data_GP[i]))\n",
    "\n",
    "        if claimedtype[i] == 0:\n",
    "            input[1].append(list(data_GP[i]))\n",
    "        if claimedtype[i] == 1:\n",
    "            input[2].append(list(data_GP[i]))\n",
    "\n",
    "    for i in range(len(input)):\n",
    "      \n",
    "        input[i] = np.array(input[i])\n",
    "\n",
    "        print(i, input[i].shape)\n",
    "\n",
    "        #insert 0 in front of the list and then truncate the end\n",
    "        for j in range(input[i].shape[0]):\n",
    "            #print(input[i][j][0][0])\n",
    "            for k in range(int(25+input[i][j][0][0])):\n",
    "                for l in range(3):\n",
    "                    #print(input[i][j][l+1])\n",
    "                    #print(input[i][j][l+1])\n",
    "                    #input[i][j][l+1] = np.insert(input[i][j][l+1], 0, input[i][j][l+1][0])[:96]\n",
    "                    input[i][j][l+1] = np.insert(input[i][j][l+1], 0, 0)[:96]\n",
    "                    #input[i][j][l+1] = input[i][j][l+1][0:100]\n",
    "            \n",
    "\n",
    "        #normalize np array along time by range\n",
    "        '''for j in range(input[i].shape[0]):\n",
    "            input[i][j,0,:] = input[i][j,0,:]/(np.max(input[i][j,0,:]) - np.min(input[i][j,0,:]))'''\n",
    "        #print(i, input[i][:,0,:])\n",
    "\n",
    "        input[i]       = K.cast_to_floatx(input[i].transpose((0, 2, 1)))\n",
    "        input[i]       = np.repeat(input[i][:,:,1:-3], rep, axis=1)\n",
    "        input[i]       = np.reshape(input[i],(input[i].shape[0], int(input[i].shape[1]/rep), int(input[i].shape[2]*rep), 1))\n",
    "\n",
    "        input_train[i] = input[i][:int(split_portion*len(input[i])),:,:,:]\n",
    "        input_test[i]  = input[i][int(split_portion*len(input[i])):,:,:,:]\n",
    "\n",
    "        type_train[i]  = claimedtype[:int(split_portion*len(input[i]))]\n",
    "        type_test[i]   = claimedtype[int(split_portion*len(input[i])):]\n",
    "\n",
    "    for i in range(len(input)-1):\n",
    "        print(f'For type {claimedtype[i]}, total size of data is {input[i].shape}, training size is {input_train[i].shape}, testing size is {input_test[i].shape}')\n",
    "\n",
    "    return input, input_train, input_test, type_train, type_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, input_train, input_test, type_train, type_test = create_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "pos = plt.imshow(input_train[0][i].reshape(96, 96).T, aspect='auto', cmap='BrBG')\n",
    "fig.colorbar(pos)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "color1 = ['seagreen', 'crimson', 'maroon']\n",
    "plt.gca().invert_yaxis()\n",
    "for j in range(3):\n",
    "    plt.scatter(np.linspace(0, 96, 96), input_train[0][i][:,j,:], s=10, marker='o', color=color1[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnae(input, d=64):\n",
    "\n",
    "    w = input[0].shape[1]\n",
    "    h = input[0].shape[2]\n",
    "\n",
    "    input_seq = keras.Input(shape=(w, h, 1))\n",
    "\n",
    "    # Encoder\n",
    "    x = layers.BatchNormalization()(input_seq)\n",
    "    x = layers.Conv2D(d, (3, 3), activation=layers.LeakyReLU(), padding=\"same\")(x) # 96*96*64\n",
    "    x = layers.MaxPooling2D((2, 2), padding=\"same\")(x) # 48*48*64\n",
    "    x = layers.Conv2D(d, (3, 3), activation=layers.LeakyReLU(), padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding=\"same\")(x) # 24*24*64\n",
    "    x = layers.Conv2D(d, (3, 3), activation=layers.LeakyReLU(), padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding=\"same\")(x) # 12*12*64\n",
    "    x = layers.Conv2D(d, (3, 3), activation=layers.LeakyReLU(), padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding=\"same\")(x) # 6*6*64\n",
    "    x = layers.Conv2D(d, (3, 3), activation=layers.LeakyReLU(), padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding=\"same\")(x) # 3*3*64\n",
    "    x = layers.Conv2D(d, (3, 3), activation=layers.LeakyReLU(), padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((3, 3), padding=\"same\")(x) # 1*1*64\n",
    "    x = layers.Flatten()(x) # 64\n",
    "    encoded = layers.Dense(d, activation='linear')(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = layers.Reshape((1, 1, d), input_shape=(d,))(encoded) # 1*1*64\n",
    "    x = layers.Conv2DTranspose(d, (3, 3), strides=3, activation=layers.LeakyReLU(), padding=\"same\")(x) # 3*3*64\n",
    "    x = layers.Conv2DTranspose(d, (3, 3), strides=2, activation=layers.LeakyReLU(), padding=\"same\")(x) # 6*6*64\n",
    "    x = layers.Conv2DTranspose(d, (3, 3), strides=2, activation=layers.LeakyReLU(), padding=\"same\")(x) # 12*12*64\n",
    "    x = layers.Conv2DTranspose(d, (3, 3), strides=2, activation=layers.LeakyReLU(), padding=\"same\")(x) # 24*24*64\n",
    "    x = layers.Conv2DTranspose(d, (3, 3), strides=2, activation=layers.LeakyReLU(), padding=\"same\")(x) # 48*48*64\n",
    "    x = layers.Conv2DTranspose(d, (3, 3), strides=2, activation=layers.LeakyReLU(), padding=\"same\")(x) # 96*96*64\n",
    "    decoded = layers.Conv2D(1, (3, 3), activation=\"tanh\", padding=\"same\")(x)\n",
    "\n",
    "    autoencoder = keras.Model(input_seq, decoded)\n",
    "    encoder = keras.Model(input_seq, encoded)\n",
    "\n",
    "    opt = Adam(learning_rate=0.0001)\n",
    "\n",
    "    autoencoder.compile(optimizer=opt, loss=\"mse\")\n",
    "    print(autoencoder.summary())\n",
    "\n",
    "    return autoencoder, encoder\n",
    "\n",
    "def cnnae_train(autoencoder, input_tmp, patience=10, epochs=100):\n",
    "    \n",
    "    callbacks = EarlyStopping(monitor='val_loss', min_delta=0, patience=patience,\n",
    "                        verbose=0, mode='min', baseline=None,\n",
    "                        restore_best_weights=True)\n",
    "\n",
    "    history = autoencoder.fit(\n",
    "                          x=input_tmp,\n",
    "                          y=input_tmp,\n",
    "                          validation_split = 0.1,\n",
    "                          epochs=epochs,\n",
    "                          verbose=1,\n",
    "                          callbacks=[callbacks])\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.grid()\n",
    "    plt.ylim(0, 1e-2)\n",
    "\n",
    "    os.chdir('/home/ricky/RNNAE')\n",
    "    plt.show()\n",
    "    #plt.savefig('CNN training history.pdf')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(x):\n",
    "\n",
    "    x = np.load(f'{x}.npy', allow_pickle=True)\n",
    "    x = np.asarray(x).astype('float32')\n",
    "\n",
    "    return x\n",
    "\n",
    "def cnnae_test(autoencoder, input_tmp):\n",
    "\n",
    "    pred = autoencoder.predict(x=input_tmp, verbose=1)\n",
    "    pred_loss = autoencoder.evaluate(x=input_tmp, y=input_tmp, verbose=1)\n",
    "\n",
    "    return pred, pred_loss\n",
    "\n",
    "def latent_space_demo(encoder, input_tmp):\n",
    "\n",
    "    latent_space = encoder.predict(input_tmp, verbose=1)\n",
    "\n",
    "    os.chdir('/home/ricky/RNNAE/CNN_latent_space_graph')\n",
    "\n",
    "    '''for i in range(latent_space.shape[1] - 1):\n",
    "        for j in range(latent_space.shape[1] - 1 - i):\n",
    "            fig = plt.figure(figsize=(6, 6))\n",
    "            plt.grid()\n",
    "            plt.scatter(latent_space[:,i], latent_space[:,i+j+1], s=8)\n",
    "            plt.title(f'id {i} vs id {i+j+1}.pdf')\n",
    "            plt.savefig(f'id_{i}_vs_id_{i+j+1}.pdf')\n",
    "            plt.close()'''\n",
    "\n",
    "    return latent_space\n",
    "\n",
    "def isolation_forest(latent_space, n_tree, split):\n",
    "\n",
    "    clf = IsolationForest(n_estimators=n_tree, warm_start=True)\n",
    "    clf.fit(latent_space)\n",
    "    anomaly = clf.score_samples(latent_space)\n",
    "    anomaly_id = np.argsort(anomaly)\n",
    "\n",
    "    shutil.rmtree('/home/ricky/RNNAE/CNN_anomaly_graph')\n",
    "    os.makedirs('/home/ricky/RNNAE/CNN_anomaly_graph')\n",
    "\n",
    "    for i, ano in enumerate(anomaly_id):\n",
    "        shutil.copy(f'/home/ricky/RNNAE/GP_graph/{data_meta_GP[ano+split][-1]}.pdf', f'/home/ricky/RNNAE/CNN_anomaly_graph/{i}_{data_meta_GP[ano+split][-1]}.pdf')\n",
    "\n",
    "    return\n",
    "\n",
    "def reconstruction_graph(input_tmp, yhat, split, filters=['g', 'r', 'i']):\n",
    "\n",
    "    color1 = ['seagreen', 'crimson', 'maroon']\n",
    "    color2 = ['darkgreen', 'firebrick', 'darkred']\n",
    "\n",
    "    shutil.rmtree('/home/ricky/RNNAE/CNN_reconstruction_graph')\n",
    "    os.makedirs('/home/ricky/RNNAE/CNN_reconstruction_graph')\n",
    "\n",
    "    for i in tqdm(range(input_tmp.shape[0])):\n",
    "\n",
    "        os.chdir('/home/ricky/RNNAE/CNN_reconstruction_graph')\n",
    "\n",
    "        isExist = os.path.exists(f'./{data_meta_GP[i+split][-1]}')\n",
    "\n",
    "        if not isExist:\n",
    "            os.makedirs(f'./{data_meta_GP[i+split][-1]}')\n",
    "            os.chdir(f'./{data_meta_GP[i+split][-1]}')\n",
    "\n",
    "        fig, axs = plt.subplots(3, figsize=(12, 18))\n",
    "\n",
    "        fig.suptitle('Images of CNN')\n",
    "        axs[0].set_title('input test image')\n",
    "        axs[1].set_title('reconstructed test image')\n",
    "        axs[2].set_title('difference')\n",
    "\n",
    "        a1 = axs[0].imshow(input_tmp[i].reshape(200,64).T, interpolation='nearest', aspect='auto')\n",
    "        a2 = axs[1].imshow(yhat[i].reshape(200,64).T, interpolation='nearest', aspect='auto')\n",
    "        a3 = axs[2].imshow((input_tmp[i] - yhat[i]).reshape(200,64).T, interpolation='nearest', aspect='auto')\n",
    "\n",
    "        fig.savefig(f'./{data_meta_GP[i][-1]}.pdf', bbox_inches='tight')\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "        for j, filter in enumerate(filters):\n",
    "            fig = plt.figure(figsize=(12, 8))\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "            plt.gca().invert_yaxis()\n",
    "\n",
    "            # And a corresponding grid\n",
    "            ax.grid(which='major', alpha=0.8)\n",
    "            ax.grid(which='minor', alpha=0.3)\n",
    "\n",
    "            plt.xlabel('Timestep', fontsize=15)\n",
    "            plt.ylabel('Absolute Magnitude', fontsize=15)\n",
    "\n",
    "            plt.xlim(-50, 200)\n",
    "\n",
    "            plt.title(f'{data_meta_GP[i+split][-1]}, {data_meta_GP[i+split][-2]}, {filter}')\n",
    "\n",
    "            #plt.errorbar(data_GP[i+split][0], data_GP[i+split][j+1], y_err=data_GP[i+split][j+4], fmt='v')\n",
    "\n",
    "            plt.scatter(data_GP[i+split,0,:], input_tmp[i][:,j,:data_meta_GP[i+split][0]], s=2, marker='o', color=color1[j], label=f'test data'.format('o'))\n",
    "            plt.scatter(data_GP[i+split,0,:], yhat[i][:,j,:data_meta_GP[i+split][0]], s=12, marker='X', color=color2[j], label=f'reconstruction'.format('X'))\n",
    "            \n",
    "            plt.legend()\n",
    "\n",
    "            plt.savefig(f'./{data_meta_GP[i][-1]}_{filter}_band.pdf')\n",
    "\n",
    "            plt.close()\n",
    "\n",
    "    return\n",
    "\n",
    "def cnn_predict(autoencoder, encoder, input_tmp, **kwargs):\n",
    "\n",
    "    split = int(0.8*(data_GP.shape[0]))\n",
    "\n",
    "    if kwargs['training_data']:\n",
    "        split = 0\n",
    "\n",
    "    pred, pred_loss = cnnae_test(autoencoder, input_tmp)\n",
    "\n",
    "    if kwargs['reconstruct_graph']:\n",
    "        print('Plotting reconstruction graphs...')\n",
    "        reconstruction_graph(input_tmp, pred, split)\n",
    "\n",
    "    return pred, pred_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, input_train, input_test, type_train, type_test = create_input(rep=32)\n",
    "\n",
    "os.chdir('/home/ricky/RNNAE/CNN_product/CNN_npy')\n",
    "np.save('input.npy', np.array(input, dtype=object))\n",
    "np.save('input_train.npy', np.array(input_train, dtype=object))\n",
    "np.save('input_test.npy', np.array(input_test, dtype=object))\n",
    "np.save('type_train.npy', np.array(type_train, dtype=object))\n",
    "np.save('type_test.npy', np.array(type_test, dtype=object))\n",
    "\n",
    "pred_loss_total = 0\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    autoencoder, encoder = cnnae(input, d=64)\n",
    "    cnnae_train(autoencoder, input_train[0], epochs=1000)\n",
    "    pred, pred_loss = cnn_predict(autoencoder, encoder, input_test[0], reconstruct_graph=False, training_data=False)\n",
    "\n",
    "    pred_loss_total += pred_loss\n",
    "\n",
    "print('pred_loss_total is', pred_loss_total)\n",
    "\n",
    "'''autoencoder.save('/home/ricky/RNNAE/CNN_autoencoder_model')\n",
    "encoder.save('/home/ricky/RNNAE/CNN_encoder_model')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=7\n",
    "\n",
    "fig, axs = plt.subplots(3, figsize=(15, 20))\n",
    "\n",
    "fig.suptitle('Images of CNN')\n",
    "axs[0].set_title('input test image')\n",
    "axs[1].set_title('reconstructed test image')\n",
    "axs[2].set_title('difference')\n",
    "\n",
    "a0 = axs[0].imshow(input_test[0][i].reshape(96,96).T, interpolation='nearest', aspect='auto', cmap='BrBG')\n",
    "a1 = axs[1].imshow(pred[i].reshape(96,96).T, interpolation='nearest', aspect='auto', cmap='BrBG')\n",
    "a2 = axs[2].imshow((input_test[0][i] - pred[i]).reshape(96,96).T, interpolation='nearest', aspect='auto', cmap='BrBG')\n",
    "\n",
    "fig.colorbar(a0, ax=axs[0])\n",
    "fig.colorbar(a1, ax=axs[1])\n",
    "fig.colorbar(a2, ax=axs[2])\n",
    "\n",
    "plt.show()\n",
    "#fig.savefig(f'./{data_meta_GP[i][-1]}.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.close()\n",
    "\n",
    "filters=['g', 'r', 'i']\n",
    "split = int(0.8*(data_GP.shape[0]))\n",
    "\n",
    "color1 = ['seagreen', 'crimson', 'maroon']\n",
    "color2 = ['darkgreen', 'firebrick', 'darkred']\n",
    "\n",
    "for j, filter in enumerate(filters):\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    # And a corresponding grid\n",
    "    ax.grid(which='major', alpha=0.8)\n",
    "    ax.grid(which='minor', alpha=0.3)\n",
    "\n",
    "    plt.xlabel('Timestep', fontsize=15)\n",
    "    plt.ylabel('Absolute Magnitude', fontsize=15)\n",
    "\n",
    "    plt.title(f'{data_meta_GP[i+split][-1]}, {data_meta_GP[i+split][-2]}, {filter}')\n",
    "\n",
    "    #plt.errorbar(data_GP[i+split][0], data_GP[i+split][j+1], y_err=data_GP[i+split][j+4], fmt='v')\n",
    "\n",
    "    plt.scatter(np.linspace(0, 96, 96), input_test[0][i][:,j,:], s=2, marker='o', color=color1[j], label=f'test data'.format('o'))\n",
    "    plt.scatter(np.linspace(0, 96, 96), pred[i][:,j,:], s=12, marker='X', color=color2[j], label=f'reconstruction'.format('X'))\n",
    "    \n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    #plt.savefig(f'./{data_meta_GP[i+split][-1]}_{filter}_band.pdf')\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space = encoder.predict(input_test[0], verbose=1)\n",
    "#latent_space = encoder.predict(input_test[0], verbose=1).T\n",
    "print(latent_space.shape)\n",
    "\n",
    "'''import sklearn.manifold as m\n",
    "\n",
    "embedded = m.TSNE(n_components=2).fit_transform(latent_space).T\n",
    "print(embedded.shape)\n",
    "plt.scatter(embedded[0], embedded[1], s=6)\n",
    "plt.show()'''\n",
    "\n",
    "for i in range(latent_space.shape[1] - 1):\n",
    "        for j in range(latent_space.shape[1] - 1 - i):\n",
    "            fig = plt.figure(figsize=(6, 6))\n",
    "            plt.grid()\n",
    "            plt.scatter(latent_space[:,i], latent_space[:,i+j+1], s=8)\n",
    "            plt.title(f'id {i} vs id {i+j+1}')\n",
    "            #plt.show()\n",
    "            #plt.savefig(f'id_{i}_vs_id_{i+j+1}.pdf')\n",
    "            plt.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d38db61bd0f0a89a9ee81948d0be9859cbe58b6eac829022af206d8fc3e92df7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tfgpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
