{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ricky/RNNAE/plasticc_csv\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/ricky/RNNAE/plasticc_csv')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_cols_meta = ['object_id', 'ddf_bool','target',\n",
    "       'true_target', 'true_submodel', 'true_z', 'true_distmod',\n",
    "       'true_lensdmu', 'true_peakmjd',\n",
    "        ]\n",
    "\n",
    "req_cols = ['object_id', 'mjd', 'passband', 'flux', 'flux_err']\n",
    "\n",
    "data_meta = pd.read_csv('plasticc_test_metadata.csv', usecols=req_cols_meta, low_memory=False)\n",
    "data = pd.read_csv('plasticc_test_lightcurves_02.csv', usecols=req_cols, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object_id    0\n",
       "mjd          0\n",
       "passband     0\n",
       "flux         0\n",
       "flux_err     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['object_id', 'ddf_bool', 'target', 'true_target', 'true_submodel',\n",
      "       'true_z', 'true_distmod', 'true_lensdmu', 'true_peakmjd'],\n",
      "      dtype='object')\n",
      "Index(['object_id', 'mjd', 'passband', 'flux', 'flux_err'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_meta.columns)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32926 378922\n"
     ]
    }
   ],
   "source": [
    "min = np.min(data.object_id)\n",
    "#min_id = np.argmin(data.object_id)\n",
    "#print(min, min_id)\n",
    "\n",
    "max = np.max(data.object_id)\n",
    "#max_id = np.argmax(data.object_id)\n",
    "#print(max, max_id)\n",
    "\n",
    "min_id = list(data_meta[data_meta.object_id == min].object_id.index)[0]\n",
    "max_id = list(data_meta[data_meta.object_id == max].object_id.index)[0]\n",
    "\n",
    "print(min_id, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140 130 126 ... 134 108 142]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5ba7e0dfe64210832b30e61ef07156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59583.2493, 59585.3547, 59586.3595, 59590.3573, 59597.1711, 59614.2014, 59615.3783, 59629.3124, 59650.0262, 59658.0486, 59660.1741, 59663.1842, 59682.0658, 59684.1371, 59686.0893, 59698.9682, 59712.0934, 59713.0721, 59769.9638, 59899.3524, 59902.3542, 59903.3445, 59914.3118, 59914.3486, 59917.3393, 59918.3164, 59922.3132, 59924.3146, 59927.3007, 59930.3271, 59931.3482, 59932.3233, 59934.3444, 59935.2752, 59938.3063, 59941.269, 59953.3005, 59957.3304, 59964.1966, 59965.2271, 59973.2882, 59976.1232, 59976.2992, 59979.2119, 59980.2042, 59986.3184, 59994.1876, 59995.0852, 59999.1247, 60002.1365, 60008.197, 60011.1804, 60012.3005, 60016.0589, 60017.1047, 60017.2486, 60018.0503, 60019.2211, 60026.0514, 60027.0839, 60032.0596, 60039.184, 60040.1296, 60041.1914, 60045.2092, 60053.039, 60066.1289, 60068.0589, 60070.1226, 60072.0973, 60073.0361, 60095.0505, 60096.0488, 60101.0262, 60102.0136, 60264.3572, 60270.3333, 60280.3506, 60285.3417, 60290.2995, 60296.3406, 60297.3181, 60309.3449, 60312.3571, 60315.2527, 60316.2677, 60319.3575, 60323.3642, 60329.2067, 60331.1724, 60331.2481, 60332.1919, 60332.316, 60341.2205, 60345.1297, 60346.1913, 60359.0899, 60363.09, 60364.2559, 60367.1531, 60368.2349, 60372.1945, 60373.2341, 60382.1495, 60392.1721, 60395.0753, 60396.1915, 60421.1168, 60426.1522, 60427.0719, 60428.0663, 60428.1606, 60428.9685, 60428.997, 60429.1017, 60434.0826, 60436.0429, 60454.0179, 60459.038, 60464.9615, 60467.0138, 60491.9654, 60491.9782, 60493.9755, 60495.9805, 60634.3437, 60641.3204, 60645.3054, 60648.3464, 60650.3458, 60651.2982, 60656.2777, 60657.3117, 60659.3113, 60661.3035, 60669.3578, 60671.2755, 60672.2385, 60672.2571, 60673.2287]\n"
     ]
    }
   ],
   "source": [
    "time = [[[] for j in range(6)] for i in data_meta.object_id[min_id:max_id]]\n",
    "\n",
    "value, counts = np.unique(data.object_id, return_counts=True)\n",
    "print(counts)\n",
    "\n",
    "for i, oid in tqdm(enumerate(data_meta.object_id[min_id:max_id])):\n",
    "    time[i][0] = list(data.mjd[i:i+counts[i]])\n",
    "\n",
    "print(time[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avoid_non_SNIa(ii, csv_data_meta):\n",
    "    \n",
    "    SN_type = csv_data_meta.true_target[ii]\n",
    "\n",
    "    if SN_type == 90:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def avoid_empty_SN(ii, oid, oid_count_elem, filters, \n",
    "    csv_data, csv_data_meta,\n",
    "    num=10, lc_length_prepeak=-250, lc_length_postpeak=250):\n",
    "\n",
    "    t = [ [] for i in filters]\n",
    "    m_app = [ [] for i in filters]\n",
    "\n",
    "    band = csv_data.passband[ii:ii+oid_count_elem]\n",
    "    \n",
    "    N_specified_bands = 0\n",
    "\n",
    "    #print('index', ii)\n",
    "    \n",
    "    for i, f in enumerate(filters):\n",
    "\n",
    "        band_id = np.where(band == f)\n",
    "\n",
    "        t[i] = np.array(csv_data.mjd.iloc[band_id[0]])\n",
    "        m_app[i] = np.array(csv_data.flux.iloc[band_id[0]])\n",
    "\n",
    "    t_max = csv_data_meta.true_peakmjd[ii]\n",
    "    #print(t_max)\n",
    "\n",
    "    for i in range(len(filters)):\n",
    "        t_duration = np.where((t[i] > (t_max + lc_length_prepeak)) & (t[i] < (t_max + lc_length_postpeak)))\n",
    "        if t_duration[0].shape[0] == 0:\n",
    "                return False\n",
    "        else:\n",
    "            N_specified_bands += t_duration[0].shape[0]\n",
    "\n",
    "    #print(N_specified_bands)\n",
    "    if N_specified_bands > num:\n",
    "        try:\n",
    "            csv_data_meta.true_distmod[ii]\n",
    "            csv_data_meta.true_z[ii]\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "    else:\n",
    "        #print('tiny', ii)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LC_Preprocess:\n",
    "\n",
    "    def __init__(self, ii, oid, oid_count_elem, filters, \n",
    "        csv_data, csv_data_meta):\n",
    "        \n",
    "        self.ii = ii\n",
    "        self.oid = oid\n",
    "        self.oid_count_elem = oid_count_elem\n",
    "\n",
    "        self.filters = filters\n",
    "\n",
    "        self.data = csv_data\n",
    "        self.data_meta = csv_data_meta\n",
    "\n",
    "        self.band = self.data.passband[ii:ii+oid_count_elem]\n",
    "        self.claimedtype = 0\n",
    "\n",
    "        self.t = [ [] for filter in self.filters]\n",
    "        self.flux = [ [] for filter in self.filters]\n",
    "        self.flux_err = [ [] for filter in self.filters]\n",
    "        self.m = [ [] for filter in self.filters]\n",
    "        self.m_err = [ [] for filter in self.filters]\n",
    "\n",
    "    def peak_alignment(self, lc_length_prepeak=-200, lc_length_postpeak=200):\n",
    "\n",
    "        self.t_peak = self.data_meta.true_peakmjd[self.ii]\n",
    "\n",
    "        for i, f in enumerate(self.filters):\n",
    "\n",
    "            self.t[i] = np.array(self.t[i]) - self.t_peak\n",
    "\n",
    "            self.t[i]     = np.delete(self.t[i], np.where(self.t[i] > lc_length_postpeak))\n",
    "            self.m[i]     = self.m[i][0:len(self.t[i])]\n",
    "            self.m_err[i] = self.m_err[i][0:len(self.t[i])]\n",
    "\n",
    "            self.t[i]     = np.delete(self.t[i], np.where(self.t[i] < lc_length_prepeak))\n",
    "            self.m[i]     = self.m[i][len(self.m[i]) - len(self.t[i]):]\n",
    "            self.m_err[i] = self.m_err[i][len(self.m_err[i]) - len(self.t[i]):]\n",
    "\n",
    "            if (len(self.t[i]) - len(self.m[i])) != 0:\n",
    "                print('bruh')\n",
    "\n",
    "        return self.t, self.m, self.m_err, self.claimedtype\n",
    "\n",
    "    def lc_graph(self, colors = ['darkcyan', 'limegreen', 'crimson'], lc_length_prepeak=-200, lc_length_postpeak=200):\n",
    "        \n",
    "        plt.plot(figsize=(16,12))\n",
    "\n",
    "        for i, filter in enumerate(self.filters):\n",
    "            plt.errorbar(self.t[i], self.m[i], self.m_err[i], label=filter, color=colors[i], fmt='.')\n",
    "        \n",
    "        plt.title(f'{self.oid}, {self.claimedtype}')\n",
    "        plt.xlim(lc_length_prepeak, lc_length_postpeak)\n",
    "        plt.ylim(-23, -14)\n",
    "        plt.xlabel('time (day)')\n",
    "        plt.ylabel('absolute magnitude')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.savefig(f'/home/ricky/RNNAE/import_graph/{self.oid}.pdf')\n",
    "        #plt.savefig(fr'C:\\\\Users\\\\ricky\\\\FYP\\\\RNNAE_public\\\\import_graph\\\\{self.SN_name}.pdf')\n",
    "        plt.clf()\n",
    "\n",
    "    def lc_extractor(self, **kwargs):\n",
    "        \n",
    "        dist_mod = float(self.data_meta.true_distmod[self.ii])\n",
    "\n",
    "        z = float(self.data_meta.true_z[self.ii])\n",
    "\n",
    "        self.claimedtype = self.data_meta.true_target[self.ii]\n",
    "\n",
    "        f_min = 0\n",
    "\n",
    "        for i, f in enumerate(self.filters):\n",
    "\n",
    "            band_id = np.where(self.band == f)\n",
    "\n",
    "            self.t[i] = np.array(self.data.mjd.iloc[band_id[0]])\n",
    "            self.flux[i] = np.array(self.data.flux.iloc[band_id[0]])\n",
    "            self.flux_err[i] = np.array(self.data.flux_err.iloc[band_id[0]])\n",
    "            \n",
    "            if np.min(self.flux[i]) < f_min:\n",
    "                f_min = np.min(self.flux[i])\n",
    "\n",
    "        for i, f in enumerate(self.filters):\n",
    "\n",
    "            self.flux[i] -= f_min\n",
    "            self.flux[i] = np.where(self.flux[i] == 0, 1e-6, self.flux[i])\n",
    "            self.m[i] = self.flux[i]\n",
    "            self.m_err[i] = self.flux_err[i]\n",
    "            '''self.m[i] = -2.5*np.log10(self.flux[i]) - dist_mod + 2.5*np.log10(1+z) + 27.5\n",
    "            self.flux[i] += f_min\n",
    "            self.m_err[i] = 2.5*0.434*(np.absolute(self.flux_err[i]/(self.flux[i])))'''\n",
    "        \n",
    "        print(np.array(self.flux_err)/np.array(self.flux))\n",
    "\n",
    "        if kwargs['peak_alignment']:\n",
    "            LC_Preprocess.peak_alignment(self)\n",
    "\n",
    "        if kwargs['LC_graph']:\n",
    "            LC_Preprocess.lc_graph(self)\n",
    "\n",
    "        return self.t, self.m, self.m_err, self.claimedtype, self.oid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    min = np.min(data.object_id)\n",
    "    max = np.max(data.object_id)\n",
    "\n",
    "    min_id = list(data_meta[data_meta.object_id == min].object_id.index)[0]\n",
    "    max_id = list(data_meta[data_meta.object_id == max].object_id.index)[0]\n",
    "\n",
    "    value, counts = np.unique(data.object_id, return_counts=True)\n",
    "\n",
    "    t_all = []\n",
    "    m_all = []\n",
    "    m_err_all = []\n",
    "    claimedtype_all = []\n",
    "    SN_name_all = []\n",
    "\n",
    "    filters_all = [1, 2, 3]\n",
    "    num_extracted_SN = 0\n",
    "\n",
    "    print('Screening and extracting SNe ...')\n",
    "    \n",
    "    for ii, oid in tqdm(enumerate(data_meta.object_id[min_id:min_id+4])):\n",
    "\n",
    "        csv_QC1 = avoid_non_SNIa(ii, data_meta)\n",
    "        #print(csv_QC1)\n",
    "        csv_QC2 = avoid_empty_SN(ii, oid, counts[ii], filters_all, \n",
    "                    data, data_meta,\n",
    "                    num=10, lc_length_prepeak=-200, lc_length_postpeak=200)\n",
    "        \n",
    "        '''if csv_QC2 is True:\n",
    "            print(csv_QC2)'''\n",
    "\n",
    "        '''if csv_QC1:\n",
    "            num_extracted_SN += 1'''\n",
    "            \n",
    "        if (csv_QC1 and csv_QC2):\n",
    "\n",
    "            LC_result = LC_Preprocess(ii, oid, counts[ii], filters_all, data, data_meta).lc_extractor(peak_alignment=True, LC_graph=True)\n",
    "            \n",
    "            t_all.append(LC_result[0])\n",
    "            m_all.append(LC_result[1])\n",
    "            m_err_all.append(LC_result[2])\n",
    "            claimedtype_all.append(LC_result[3])\n",
    "            SN_name_all.append(LC_result[4])\n",
    "            \n",
    "            num_extracted_SN += 1\n",
    "\n",
    "    os.chdir('/home/ricky/RNNAE/import_npy')\n",
    "    #os.chdir(r'C:\\\\Users\\\\ricky\\\\FYP\\\\RNNAE_public\\\\import_npy')\n",
    "    print('The current working directory is', os.getcwd())\n",
    "\n",
    "    np.save('Time_all.npy', np.array(t_all, dtype=object))\n",
    "    np.save('Magnitude_Abs_all.npy', np.array(m_all, dtype=object))\n",
    "    np.save('Magnitude_Abs_err_all.npy', np.array(m_err_all, dtype=object))\n",
    "    np.save('Type_all.npy', np.array(claimedtype_all))\n",
    "    np.save('SN_name.npy', np.array(SN_name_all))\n",
    "\n",
    "    print(f'There are {num_extracted_SN} extracted SNe')\n",
    "    print('End of import.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screening and extracting SNe ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c08618585e45bbb6237e4e369f468f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.21246681, 0.60527556, 2.19857904, 0.37115121, 0.1021621 ,\n",
      "       0.08307151, 0.19051656, 0.03123038, 0.54651137, 0.09574328,\n",
      "       0.18155912, 0.06959933, 0.10904542])\n",
      " array([0.29591049, 0.20219412, 0.05937335, 0.26996102, 0.05885232,\n",
      "       0.47409071, 0.60241718, 0.08017243, 0.64183649, 0.0472214 ,\n",
      "       0.56763024, 0.32103765, 0.16346734, 0.07327796, 1.10648186,\n",
      "       0.28794751, 0.14623407, 0.49281993, 0.19628323, 0.40619443,\n",
      "       0.07347621, 0.49464915])\n",
      " array([6.35933887e-01, 5.54827840e-01, 1.68292760e-01, 2.02157989e-01,\n",
      "       5.28017376e-02, 6.77579755e-02, 4.17795109e-01, 2.94591880e+07,\n",
      "       3.42530897e-01, 1.12129196e-01, 1.70566569e-01, 3.80394742e-02,\n",
      "       1.48391236e-01, 5.75731281e-01, 1.52735775e-01, 8.45346029e-02,\n",
      "       2.47085463e-01, 1.67990172e+00, 5.42424786e-01, 8.53819057e-02,\n",
      "       1.04674754e-01, 1.47087452e-01, 6.99953506e-02])]\n",
      "The current working directory is /home/ricky/RNNAE/import_npy\n",
      "There are 1 extracted SNe\n",
      "End of import.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-420-74d769d5dd35>:95: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  print(np.array(self.flux_err)/np.array(self.flux))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d38db61bd0f0a89a9ee81948d0be9859cbe58b6eac829022af206d8fc3e92df7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tfgpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
